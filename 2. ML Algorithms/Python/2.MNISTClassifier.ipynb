{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Hand Written Numbers Classifier\n",
    "\n",
    "Another classification example to recognize hand written numbers. Trained using MNIST dataset.\n",
    "\n",
    "After training the model, you can use Sample_Sketching sketch in Processing to write numbers and see the results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install a required library to use OSC protocol\n",
    "!pip install pyosc\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup OSC Protocol to communicate with Processing\n",
    "import OSCHelper\n",
    "from OSC import OSCMessage\n",
    "server=OSCHelper.createServer(9000)\n",
    "client=OSCHelper.createClient(4200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def create_model(nbclasses,firstLayer,layers):\n",
    "    model=models.Sequential()\n",
    "    model.add(Dense(firstLayer,activation='relu',input_shape=(784,)))\n",
    "    for l in layers:\n",
    "        model.add(Dense(l,activation='relu'))\n",
    "    model.add(Dense(nbclasses,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup training data. Here we using MNIST dataset for numbers\n",
    "# the training set is 28x28 input, and a number 0~9 as output\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#scale training input from 0~255 -> 0~1 by dividing on 255 \n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n",
    "\n",
    "nb_classes=10\n",
    "\n",
    "#convert the input from 2D arrays to 1D arrays\n",
    "X_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "X_test = x_test.reshape(x_test.shape[0], 28*28)\n",
    "\n",
    "#convert numbers output to one-hot encoding\n",
    "Y_train = utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = utils.to_categorical(y_test, nb_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb41de3590>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot an example image from the dataset\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index=10\n",
    "plt.imshow(x_train[index],cmap='gray')\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model=create_model(nb_classes,64,[64,32,16])\n",
    "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model.h5\")#or just load a pretrained model (trained for model arch (64,[64,32,16]) with 97% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def onOSC_Image(path, tags, args, source):\n",
    "    width=args[0]\n",
    "    height=args[1]\n",
    "    args=args[2:]\n",
    "    img=np.reshape(args,(width,height))\n",
    "    x=np.reshape(img,(width*height))\n",
    "    res=model.predict(np.array([x]))\n",
    "    print(np.argmax(res))\n",
    "    #plt.imshow(img,cmap='gray')\n",
    "    #plt.show()\n",
    "\n",
    "server.addMsgHandler( \"/inputs/image\", onOSC_Image )\n",
    "\n",
    "\n",
    "OSCHelper.start_server(server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-cpu]",
   "language": "python",
   "name": "conda-env-tf-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
