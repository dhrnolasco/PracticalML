{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO (You Only Look Once) algorithm:\n",
    "\n",
    "YOLO is an efficient algorithm for detecting multiple in a single image. It segments the image into regions, and calculates the propability for each region to belong to a specific class.\n",
    "\n",
    "Here we use this algorithm with a webcamera to label objects in the view.\n",
    "\n",
    "First, we need to install some dependences, mainly OpenCV library. A commonly used library for computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install required libraries\n",
    "!conda install python=3.5 -y\n",
    "!conda install -c menpo opencv3 -y\n",
    "!pip3 install opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to install the model weights for the network. There are many weights and configuration files can be installed, which affect the speed and precision of the detection depending on your target application. Check [YOLO website](https://pjreddie.com/darknet/yolo/) for more details about the available pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights can be downloaded from here\n",
    "#https://pjreddie.com/darknet/yolo/\n",
    "\n",
    "#!curl -O https://pjreddie.com/media/files/yolov3-tiny.weights\n",
    "#!curl -O https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg\n",
    "    \n",
    "!curl -O https://pjreddie.com/media/files/yolov3.weights\n",
    "!curl -O https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
    "    \n",
    "\n",
    "!curl -O https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Here are some helper functions to load a network, detect prediction, and draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def LoadNetwork(name=\"yolov3\"):\n",
    "    #load labels\n",
    "    with open(\"coco.names\", 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    #create the network\n",
    "    net = cv2.dnn.readNet(name+\".weights\", name+\".cfg\")\n",
    "    return net,classes\n",
    "\n",
    "def DetectObjects(net,image):\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "\n",
    "    scale = 0.001\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    outs = net.forward(output_layers)\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.3\n",
    "\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3:\n",
    "                center_x = int(detection[0] * Width)\n",
    "                center_y = int(detection[1] * Height)\n",
    "                w = int(detection[2] * Width)\n",
    "                h = int(detection[3] * Height)\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    \n",
    "    indices=[i[0] for i in indices]\n",
    "    \n",
    "    result=[]\n",
    "    \n",
    "    for i in indices:\n",
    "        result.append([class_ids[i],round(100*confidences[i]),boxes[i]])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def DrawPrediction(img,classes, class_id, confidence, x, y, x_plus_w, y_plus_h,COLORS):\n",
    "    label = \"{0}: {1}%\".format(classes[class_id],confidence)\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def DrawResults(image,classes,results,COLORS):\n",
    "    for r in results:\n",
    "        box=r[2]\n",
    "        x=round(box[0])\n",
    "        y=round(box[1])\n",
    "        w=round(box[2])\n",
    "        h=round(box[3])\n",
    "        DrawPrediction(image,classes,r[0],r[1],x,y,x+w,y+h,COLORS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions\n",
    "\n",
    "Here is the example of using the previous helper functions. First, we initiate the builtin webcamera (if you have USB camera, change the index in cv2.VideoCapture).\n",
    "\n",
    "Next we create the network, and specify the model name (depending on which model we downloaded) without the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#start webcamera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#create network\n",
    "net,classes=LoadNetwork(\"yolov3\")\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop is here, it will capture an image from the camera, detect objects, and then draw the results.\n",
    "\n",
    "Depending on your application, you can use \"results\" to check which objects were detected.\n",
    "\n",
    "Results is an array of detected objects, and each result (R) has three elements:\n",
    "* R\\[0\\]: Class index of the detected object. You can check the name of it using lookup \"classes\\[R\\[0\\]\\]\".\n",
    "* R\\[1\\]: Propability of the detected object as a percentage.\n",
    "* R\\[2\\]: Bounding box of the object (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    ret, image = cam.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results=DetectObjects(net,image)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    DrawResults(image,classes,results,COLORS)\n",
    "    cv2.putText(image, \"Detection time:{0}ms\".format(int(elapsed_time*1000)), (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "    \n",
    "    cv2.imshow(\"objects\", image)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PML",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
