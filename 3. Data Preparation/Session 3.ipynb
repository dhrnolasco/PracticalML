{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3\n",
    "\n",
    "This lecture covers the datasets and how to prepared them for training, evaluating, and testing.\n",
    "\n",
    "\n",
    "## Learning Objectives:\n",
    "* Building a dataset\n",
    "    * Download images from google service\n",
    "    * Preparing dataset folder structure\n",
    "    * Collect images from camera or by sketching them\n",
    "* Learning Model Output\n",
    "* Evaluate performance of training\n",
    "\n",
    "## Practical Examples:\n",
    "* Build a general image classifier\n",
    "* Build an audio recognition system\n",
    "\n",
    "## Required Libraries:\n",
    "__Scikit-learn__: Useful library for data processing. We use it here to split training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install scikit-learn -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Building Dataset\n",
    "\n",
    "Preparding a dataset for training can be troublesome and time consuming process. To accelerate this process, we can use online websites and search engines to build an initial dataset for training.\n",
    "\n",
    "For this session, we will use google images search engine to retrive images with specific keywords.\n",
    "<br>Google Images Downloader: [GoogleImageDownload.ipynb](./Python/GoogleImageDownload.ipynb)\n",
    "\n",
    "That notebook will help you at retriving images with selected keywords and amount. Running it will take time depending on the network connection and number of entries per category.\n",
    "\n",
    "Another way is to download an existing dataset online, most famous websites for datascience is [Kaggle](https://www.kaggle.com/). \n",
    "\n",
    "When preparding a dataset, its important to use a way to organize it. The simplist way is to use folder structure defining the labels and samples per label. For example:\n",
    "<br>__Shoes__\n",
    "<br>|-__children__\n",
    "<br>|----|- imgA.jpg\n",
    "<br>|----|- imgB.jpg\n",
    "<br>|----| ....\n",
    "<br>|----|- imgN.jpg\n",
    "<br>|-__men__\n",
    "<br>|----|- imgA.jpg\n",
    "<br>|----|- imgB.jpg\n",
    "<br>|----| ....\n",
    "<br>|----|- imgN.jpg\n",
    "<br>|-__women__\n",
    "<br>|----|- imgA.jpg\n",
    "<br>|----|- imgB.jpg\n",
    "<br>|----| ....\n",
    "<br>|----|- imgN.jpg\n",
    "\n",
    "\n",
    "When you have a complex type to train (for example, images and sensor readings combined), its best to have an excel like sheet that refers to the values of each sample. For example:\n",
    "\n",
    "|ID | Image|Color| Size | Style   |\n",
    "|---|---|---|---|---|\n",
    "| Sample 1 | ImgA.jpg | Red   | 27   | Westren |\n",
    "| Sample 2 | ImgB.jpg | Black | 29.5 | Asian   |\n",
    "| ...      | ...| ... | ...|\n",
    "\n",
    "\n",
    "\n",
    "The number of features used is reflected on the first layer's __input_shape__ of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this code here\n",
    "input_len=28*28 #length of feature vector use in the input\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(input_len,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Some helpful examples that use Processing to send images to python, and to help at building your dataset:\n",
    "* Python Notebook for building the dataset: [OSCImageDataset.ipynb](./Python/OSCImageDataset.ipynb)\n",
    "_<br>Make sure to specify the name of your dataset, and labels to be used_\n",
    "\n",
    "__Processingstreamers:__\n",
    "* Camera Images: [Camera_Streamer.pde](./Processing/Camera_Streamer/Camera_Streamer.pde)\n",
    "* Image Sketches: [Sketch_Streamer.ipynb](./Sketch_Streamer/Sketch_Streamer.pde)\n",
    "\n",
    "---\n",
    "## Learning Model Output\n",
    "\n",
    "Its important to define the output of the learning model, and by that what the network is trying to learn. Two main types of outputs exists: Discrete and Continous output.\n",
    "\n",
    "### Discrete Output\n",
    "So far we covered mainly classification problems which is a discrete learning problem, and the outputs are labels from a predefined set [L1,L2,L3,...,Ln] such as classifying animals to their categories (e.g. Cats vs Dogs).\n",
    "For this type of problems, we define the network to have outputs count equals to number of labels of the network, for example 2 outputs for Cats vs Dogs, or 10 for digit images classification. \n",
    "\n",
    "Labels are encoded using so called [one-hot-encoding](https://en.wikipedia.org/wiki/One-hot), which define a 1D vector with length equals to number of labels, and all values equals to zero excep to the index equal to the label number. For example, for [cats:0, dogs:1] labels:\n",
    "\n",
    "|Label Name | ID| One-hot-encoding   |\n",
    "|---|---|---|\n",
    "| Cats | 0  | 1 0 |\n",
    "| Dogs | 1  | 0 1   |\n",
    "\n",
    "And for 10 digits classification:\n",
    "\n",
    "|ID| One-hot-encoding   |\n",
    "|---|---|\n",
    "|0  | 1 0 0 0 0 0 0 0 0 0 |\n",
    "|1  | 0 1 0 0 0 0 0 0 0 0 |\n",
    "|2  | 0 0 1 0 0 0 0 0 0 0 |\n",
    "|3  | 0 0 0 1 0 0 0 0 0 0 |\n",
    "|...|...|\n",
    "|8  | 0 0 0 0 0 0 0 0 1 0 |\n",
    "|9  | 0 0 0 0 0 0 0 0 0 1 |\n",
    "\n",
    "We can use this function to help us convert labels to the encoding:\n",
    "\n",
    "tensorflow.keras.utils.to_categorical(Y, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 4\n",
      "1 --> [0. 1. 0. 0.]\n",
      "0 --> [1. 0. 0. 0.]\n",
      "2 --> [0. 0. 1. 0.]\n",
      "3 --> [0. 0. 0. 1.]\n",
      "1 --> [0. 1. 0. 0.]\n",
      "0 --> [1. 0. 0. 0.]\n",
      "2 --> [0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "Y=[1,0,2,3,1,0,2]\n",
    "nb_classes=len(set(Y)) #automatically calculate the number of unique labels\n",
    "print(\"Number of labels: {0}\".format(nb_classes))\n",
    "\n",
    "\n",
    "oneHotY=utils.to_categorical(Y, nb_classes)\n",
    "\n",
    "for y1,y2 in zip(Y,oneHotY):\n",
    "    print(\"{0} --> {1}\".format(y1,y2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design of the model also is reflected via the last layer added to the model, and how the model is compiled. We use a Dense layer with class count equals to the number of labels (nb_classes), and we should set the __activation__ function to __'softmax'__. This function calculates the probability distribution over the outputs to provide which label is most likely to be activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this code here\n",
    "model.add(layers.Dense(nb_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the compile, we should set the __loss__ parameter to be __'categorical_crossentropy'__, which calculates the error between the predicted labels and the provided labels as categories instead of continous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this code here\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous Output\n",
    "The other common type of training is to use continous output, such as the case of regression problems.\n",
    "Here the output should provide continous values within a specific range. For example prediction of temperature, wind speed, and humidty from a picture (maybe it might work!). So in this case, the output has three continous outputs:\n",
    "* Temperature -20~50\n",
    "* Wind speed    0~120\n",
    "* Humidty       0~100\n",
    "\n",
    "These outputs are reflected on the output layer that it should have a number of perceptrons equal to number of outputs (3 in this case), and the __activation__ function is __'linear'__:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this code here\n",
    "nb_outputs=3\n",
    "model.add(layers.Dense(nb_outputs,activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the compile function should have a __loss__ function suitable for this types of problems. Most common are:\n",
    "* 'mean_squared_error'\n",
    "* 'mean_absolute_error'\n",
    "\n",
    "And are specified as in __compile__ function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this code here\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate performance of training\n",
    "\n",
    "When training the network for specific dataset, how can we tell if it can really generalize to unseen data? Solution is simple! We split the dataset to two main parts:\n",
    "* __Train & Validation dataset (75% of all data)__: This dataset is used for training purpose, the training part of it (usually 80%) is used internally by the network to tune the weights of the layers, and the validation set (20%) is used to observe its performance and tune network parameters (layers count, number of perceptrons, ...etc). We also observe both loss functions of the training and validation while the network is training.\n",
    "\n",
    "We can use this function from scikit-learn library to split the dataset (x_dataset,y_dataset) to two datasets: train and test (its called test, but its the validation dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has a total of: 100 samples\n",
      "Training using: 80 samples\n",
      "Validating using: 20 samples\n"
     ]
    }
   ],
   "source": [
    "#Generate some random samples\n",
    "import numpy as np\n",
    "x_dataset=np.random.rand(100,20)\n",
    "y_dataset=np.random.rand(100)\n",
    "\n",
    "#split samples to training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(x_dataset,y_dataset,test_size=0.2)\n",
    "\n",
    "print(\"Dataset has a total of: {0} samples\".format(len(x_dataset)))\n",
    "print(\"Training using: {0} samples\".format(len(X_train)))\n",
    "print(\"Validating using: {0} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Test dataset (25% of all data)__: This one is used *After* the model has been trained, and this will give us the overall performance of the network for unseen data, and how it will perform on reality. \n",
    "\n",
    "In the audio and image classifier examples, the validation is used in the fit function:\n",
    "<br>*model.fit(X_train,Y_train,__validation_data=(X_test,Y_test)__,epochs=100,batch_size=8)*\n",
    "\n",
    "\n",
    "You will notice that when training, validation accuracy is also reported:\n",
    "\n",
    "<img src=\"Images/training_metrics.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "*Note*: __batch_size__ plays an important role in the speed of learning and accuracy. The batch referes to the number of samples propagated through the network for learning. Good practice to set the batch_size equals to a power of two [8,16,32,64,...]. Also, set the batch size around 5-10% of the total training samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Visualize training performance using Tensorboard\n",
    "\n",
    "\n",
    "Tensorboard is a great tool to display the performance of training your model against your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this code here! Its just to show the newly added tensorboard\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "## .... Model created, data is pre-processed and split to training (X_train, Y_train) and validation (X_test,Y_test)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,batch_size=8, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, in the command line (or terminal), access notebook location and run this command:\n",
    "__<br>tensorboard --logdir=logs/__\n",
    "\n",
    "<img src=\"Images/tensorboard_terminal.png\" width=\"50%\">\n",
    "\n",
    "Then, in the browser (chrome for example), access the following URL:\n",
    "\n",
    "[http://localhost:6006](http://localhost:6006)\n",
    "\n",
    "If the port (6006) in was different from the one in the picture, then change the port part in the URL to the new port. You can compare multiple training sessions with different hyber paramteters of the model (number of layers, number of perceptrons, ...etc) or with/without normalization. \n",
    "\n",
    "<br>This picture shows the results after tuning the network parameters to achieve best accuracy for both training and validation datasets:\n",
    "\n",
    "<img src=\"Images/tensorboard_metrics.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practical Examples\n",
    "\n",
    "### General Image Classifier:\n",
    "\n",
    "<br>[ImageClassifier.ipynb](./Python/ImageClassifier.ipynb) allows you to train on a custom dataset of images\n",
    "\n",
    "\n",
    "### Audio Recognizer:\n",
    "\n",
    "<br>[AudioRecognizer.ipynb](./Python/AudioRecognizer.ipynb) allows you to train on a custom dataset of audio files. It shows the process how to preprocess audio files for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PML",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
