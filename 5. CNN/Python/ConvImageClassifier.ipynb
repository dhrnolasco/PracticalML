{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classifier using CNN\n",
    "\n",
    "This project shows how to build an image classifier of your choice based on dataset of images you provide.\n",
    "<br>We will use Convolutional Neural Networks (CNN) this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - pydot\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    graphviz-2.40.1            |       hefbbd9a_2         6.7 MB  anaconda\n",
      "    ca-certificates-2018.03.07 |                0         124 KB  anaconda\n",
      "    pydot-1.3.0                |           py27_1          39 KB  anaconda\n",
      "    fribidi-1.0.5              |       h1de35cc_0          62 KB  anaconda\n",
      "    conda-4.5.11               |           py27_0         1.0 MB  anaconda\n",
      "    pango-1.42.4               |       h060686c_0         523 KB  anaconda\n",
      "    certifi-2018.10.15         |           py27_0         138 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    fribidi:         1.0.5-h1de35cc_0      anaconda   \n",
      "    graphviz:        2.40.1-hefbbd9a_2     anaconda   \n",
      "    pango:           1.42.4-h060686c_0     anaconda   \n",
      "    pydot:           1.3.0-py27_1          anaconda   \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    conda:           4.5.11-py27_0                     --> 4.5.11-py27_0     anaconda\n",
      "    openssl:         1.1.1a-h1de35cc_0                 --> 1.1.1-h1de35cc_0  anaconda\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    ca-certificates: 2018.11.29-ha4d7672_0 conda-forge --> 2018.03.07-0      anaconda\n",
      "    certifi:         2018.11.29-py27_0                 --> 2018.10.15-py27_0 anaconda\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "graphviz-2.40.1      | 6.7 MB    | ##################################### | 100% \n",
      "ca-certificates-2018 | 124 KB    | ##################################### | 100% \n",
      "pydot-1.3.0          | 39 KB     | ##################################### | 100% \n",
      "fribidi-1.0.5        | 62 KB     | ##################################### | 100% \n",
      "conda-4.5.11         | 1.0 MB    | ##################################### | 100% \n",
      "pango-1.42.4         | 523 KB    | ##################################### | 100% \n",
      "certifi-2018.10.15   | 138 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#install required libraries to draw model architecture\n",
    "#!conda install -c anaconda pydot -y\n",
    "!conda install -c anaconda graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, __load_dataset_from_folder__, will load image files from specific path. It will return an array of samples with their assigned label, and a list of labels.\n",
    "<br>An example of dataset folder structure is the following:\n",
    "<br>__Shoes__\n",
    "<br>|-__children__\n",
    "<br>|----|- imgA.jpg\n",
    "<br>|----|- imgB.jpg\n",
    "<br>|----| ....\n",
    "<br>|----|- imgN.jpg\n",
    "<br>|-__men__\n",
    "<br>|----|- imgA.jpg\n",
    "<br>|----|- imgB.jpg\n",
    "<br>|----| ....\n",
    "<br>|----|- imgN.jpg\n",
    "<br>|-__women__\n",
    "<br>|----|- imgA.jpg\n",
    "<br>|----|- imgB.jpg\n",
    "<br>|----| ....\n",
    "<br>|----|- imgN.jpg\n",
    "\n",
    "This will generate a dataset for shoes with labels: \n",
    "<br>children: 0\n",
    "<br>men     :1\n",
    "<br>women :2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PML\n",
    "\n",
    "TARGET_WIDTH=150\n",
    "TARGET_HEIGHT=150\n",
    "\n",
    "print(\"Loading Training Samples...\")\n",
    "samples,labels=PML.load_img_dataset_from_folder(\"datasets/catsdogs\",target_size=(TARGET_WIDTH,TARGET_HEIGHT))\n",
    "\n",
    "for i,l in enumerate(labels):\n",
    "    samples_count=len([s for s in samples if s[1]==i])\n",
    "    print(\"{0}- [{1}] with total of {2} samples\".format(i,l,samples_count))\n",
    "    \n",
    "\n",
    "#load test samples\n",
    "print(\"Loading Test Samples...\")\n",
    "sample_test,labels_test=PML.load_img_dataset_from_folder(\"test/catsdogs/\",target_size=(TARGET_WIDTH,TARGET_HEIGHT))\n",
    "for i,l in enumerate(labels_test):\n",
    "    samples_count=len([s for s in sample_test if s[1]==i])\n",
    "    print(\"{0}- [{1}] with total of {2} samples\".format(i,l,samples_count))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some random images from the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PML\n",
    "%matplotlib inline\n",
    "PML.plot_random_images(samples,labels=labels,rows=3,cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Reshape the loaded samples to a 1D vector so it can be used in the neural network, and normalize image values.\n",
    "\n",
    "Convert the labels from numbers to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import utils\n",
    "import random\n",
    "import PML\n",
    "\n",
    "#shuffle samples order\n",
    "random.shuffle(samples)\n",
    "\n",
    "#Split to input X and labels Y\n",
    "X=np.array([i[0] for i in samples])\n",
    "Y=np.array([i[1] for i in samples])\n",
    " \n",
    "#Prepared to convolutional samples (3 channels per sample)\n",
    "X=PML.prepare_conv_samples(X)\n",
    "#normalize values\n",
    "x_train,normalizer=PML.normalize_image(X)\n",
    "\n",
    "#prepare labels to one-hot-encoding\n",
    "nb_classes=len(labels)\n",
    "y_train = utils.to_categorical(Y, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(x_train,y_train,test_size=0.1)\n",
    "\n",
    "print(\"Training using: {0} samples\".format(len(X_train)))\n",
    "print(\"Validating using: {0} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Create a model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "input_shape=(TARGET_WIDTH,TARGET_HEIGHT,1)\n",
    "\n",
    "model=PML.create_conv_classify_model(input_shape,nb_classes,32,[32,64,64],[64,32],dropout=0)\n",
    "history=model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=20,batch_size=128)\n",
    "\n",
    "#export model\n",
    "PML.export_model(model,\"./models/catsdogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/PML/lib/python3.6/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-048ae38d64d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./models/catsdogs.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/PML/lib/python3.6/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    146\u001b[0m           \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m   \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m   \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PML/lib/python3.6/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PML/lib/python3.6/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     50\u001b[0m                       ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model,to_file=\"./models/catsdogs.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PML.plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Samples\n",
    "\n",
    "Load newly unseen samples to test them against the trained model. Check the accuracy of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=PML.test_samples(model,samples=sample_test,labels=labels,normalizer=normalizer,flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] OSC for realtime recognition\n",
    "\n",
    "\n",
    "You can use this to communicate with external application (Processing for example) to predict images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 315,426\n",
      "Trainable params: 315,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "TARGET_WIDTH=150\n",
    "TARGET_HEIGHT=150\n",
    "model=PML.import_model(\"./models/catsdogs\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup OSC Protocol to communicate with Processing\n",
    "import OSCHelper\n",
    "server=OSCHelper.createServer(9000)\n",
    "client=OSCHelper.createClient(4200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "\n",
    "def onOSC_Image(*args):\n",
    "    width=args[1]\n",
    "    height=args[2]\n",
    "    jpgdata=args[3]\n",
    "    file_jpgdata = io.BytesIO(jpgdata)\n",
    "    img = Image.open(file_jpgdata).resize((TARGET_WIDTH,TARGET_HEIGHT)).convert(\"L\")\n",
    "    img=np.array(img).astype(float)\n",
    "    img=img/255.0\n",
    "    x=PML.prepare_conv_samples([x])\n",
    "    res=model.predict(np.array(x))\n",
    "    label_idx=np.argmax(res)\n",
    "    client.send_message(\"/output/label\",[int(label_idx),str(labels[label_idx])])\n",
    "    #plt.imshow(img,cmap='gray')\n",
    "    #plt.title(\"Prediction:{0}\".format(labels[label_idx]))\n",
    "    #plt.show()\n",
    "\n",
    "server.addMsgHandler( \"/inputs/image\", onOSC_Image )\n",
    "\n",
    "OSCHelper.start_server(server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PML",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
