{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 5\n",
    "\n",
    "We will use in this session Convolutional Neural Networks to train image dataset. You will see that this model provides much higher level of accuracy compared with the classical Neural Networks.\n",
    "\n",
    "## Learning Objectives:\n",
    "* Understand Convolution \n",
    "* Apply Convolutional Neural Networks to extract more features\n",
    "* Use Google Colab service to train networks on cloud\n",
    "* Bonus: Face detection example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding Convolution\n",
    "\n",
    "Convolution is basically a function that aims to extract more features from the data without the use of feature engineering by human. Convolution consists of kernels that are applied on window of pixels or data points, and extracts the relationship between these data points. \n",
    "\n",
    "To visualize this process in Python, [Convolution Notebook](./Python/Convolution.ipynb) contains a sample program that loads a random image from dataset folder, applies several hand written 3x3 kernels, and displays them.\n",
    "\n",
    "Internally, the learning model automatically calculates these kernels, and typically, there are hundreds of them within the model. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Applying CNN \n",
    "\n",
    "The basic architecture to create model doesn't differ much from how you previously used to create a model. There are mainly three new layers to be used:\n",
    "* Conv2D: Applies Convolution on 2D data (such as images). \n",
    "* MaxPooling2D: Reduces the output size of previous layer. Mainly used after Conv2D layers\n",
    "* Flatten: Used just before we add Dense layers to the model. It converts the 3D output from Convolutional and MaxPooling layers to 1D vector. For example, (28,28,3) image will be flatten to 28x28x3=2352 1D vector size.\n",
    "\n",
    "The input for CNN differs from Neural Networks that it should take 3D input instead of 1D input. Since we are using images, the input for the model should be (WxHxD):\n",
    "* W: Width of the input images\n",
    "* H: Height of the input images\n",
    "* D: Depth of input images (or number of channels). For example, D=1 for grayscale images, or 3 for RGB images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Conv (Conv2D)          (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "Hidden_Conv_1 (Conv2D)       (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Hidden_Conv_2 (Conv2D)       (None, 27, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "Hidden_Conv_3 (Conv2D)       (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "Hidden_Conv_4 (Conv2D)       (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 302,658\n",
      "Trainable params: 302,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "IMAGE_WIDTH=64\n",
    "IMAGE_HEIGHT=64\n",
    "IMAGE_DEPTH=3 #RGB\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32,  #Number of kernels to be created for this layer\n",
    "                        kernel_size=(3,3), #kernel size, usually 2x2 or 3x3\n",
    "                        input_shape=(IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_DEPTH), #Input size\n",
    "                        name=\"Input_Conv\",\n",
    "                        activation='relu')) #as usual, activation function\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "#next layers don't need to specify the input_shape, it will be automatically calculated\n",
    "model.add(layers.Conv2D(filters=64,  #Number of kernels to be created for this layer\n",
    "                        kernel_size=(3,3),\n",
    "                        name=\"Hidden_Conv_1\",\n",
    "                        activation='relu'))\n",
    "model.add(layers.Conv2D(filters=64,  #Number of kernels to be created for this layer\n",
    "                        kernel_size=(3,3),\n",
    "                        name=\"Hidden_Conv_2\",\n",
    "                        activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "\n",
    "#next layers don't need to specify the input_shape, it will be automatically calculated\n",
    "model.add(layers.Conv2D(filters=128,  #Number of kernels to be created for this layer\n",
    "                        kernel_size=(3,3), \n",
    "                        name=\"Hidden_Conv_3\",\n",
    "                        activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "\n",
    "#next layers don't need to specify the input_shape, it will be automatically calculated\n",
    "model.add(layers.Conv2D(filters=128,  #Number of kernels to be created for this layer\n",
    "                        kernel_size=(3,3), \n",
    "                        name=\"Hidden_Conv_4\",\n",
    "                        activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Flatten()) #the magical layer to flatten the output of previous layers\n",
    "model.add(layers.Dense(128,activation='relu',name=\"Dense_1\")) #our NN layer\n",
    "model.add(layers.Dense(64,activation='relu',name=\"Dense_2\")) #our NN layer\n",
    "model.add(layers.Dense(2,activation='sigmoid',name=\"Output\"))# output layer of the model\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will explort a model plot to an image file\n",
    "#to run this command, you will need to install both pydot and graphviz\n",
    "#conda install -c anaconda graphviz\n",
    "#conda install -c anaconda pydot\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='images/model.png',show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The result of the model architecture looks like the following:\n",
    "<img src=\"./Images/model.png\" width=\"30%\">\n",
    "\n",
    "\n",
    "And example to use Convolution is on [MNIST handwritten digits](http://localhost:8888/notebooks/5.%20CNN/Python/CNN_MNIST.ipynb). It achives training and validation accuracy of 99~100% using CNN!\n",
    "\n",
    "One important point you will notice when training CNN is how slow the process is. To address that, you will either need a good GPU installed (and tensorflow is configured to use it), such as GTX 1060 or above. Or to use cloud based training such as Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Google Colab\n",
    "\n",
    "Google provides a free service (https://colab.research.google.com/notebook) that allows you to run python on the cloud. It contains also tensorflow and keras frameworks already preinstalled for you to use.\n",
    "\n",
    "One important thing to know, that each time you open google colab space, it will create a new virtual session. So all calculations will be removed if you refreshed the page or closed it. Its important to save your trained model to a file and download it to your PC.\n",
    "\n",
    "\n",
    "This shared notebook contains an example to train a model from dataset using Convolutional Neural Networks:\n",
    "https://drive.google.com/open?id=1a1opqViWFcu6r9WOQaznDOgMBZgfoVfF\n",
    "\n",
    "After the model is trained and exported to a file __\\[\\*\\]__ , you can load it as in the [CatsDogs_Load example](./Python/CatsDogs_Load.ipynb).\n",
    "\n",
    "__\\[\\*\\] Important Note:__ Currently, the tensorflow version used by Google Colab and the one we are using is slightly different, thus the exported file (yaml) needs to be manually edited as follow:\n",
    "* Open the yaml file using text editor (such as Atom).\n",
    "* Remove the keyword \"__layers:__\" in the fourth line\n",
    "* Remove the one before last line, usually like: __name: sequential_3__\n",
    "* Replace in all file keyword: __GlorotUniform__ to __VarianceScaling__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Face Detection\n",
    "\n",
    "Here is an exmaple for using face detection module provided by OpenCV. It can be used for building datasets of faces\n",
    "\n",
    "https://drive.google.com/open?id=1yBeXoyu22Ne8gipNG_pmkODBq5iPfdIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PML",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
